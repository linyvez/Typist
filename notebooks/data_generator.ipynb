{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZW7SpvobTwC"
      },
      "source": [
        "**Important!** Due to some libraries not being updated, this notebook requires Python 3.11 and won't work with any newer versions. Please make sure your environment meets this requirement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xynXWmO-_HX1"
      },
      "outputs": [],
      "source": [
        "!pip install \"transformers==4.42.4\" \"accelerate>=0.26.0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zdvLpwb0wn08"
      },
      "outputs": [],
      "source": [
        "!pip install TTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OorWf6BocGan"
      },
      "source": [
        "You can skip the cell below if you don't want to save the results to Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "MEWcKvOq9R31"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_N9jAbcdnAT-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from TTS.tts.layers.xtts.gpt import GPT2InferenceModel\n",
        "from transformers.generation import GenerationMixin\n",
        "import glob\n",
        "import numpy as np\n",
        "import random\n",
        "import soundfile as sf\n",
        "import torchaudio\n",
        "import shutil\n",
        "from torchaudio.datasets import LIBRISPEECH\n",
        "from pathlib import Path\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Ywoelfjuy62F"
      },
      "outputs": [],
      "source": [
        "original_load = torch.load\n",
        "\n",
        "def unsafe_load(*args, **kwargs):\n",
        "    if 'weights_only' not in kwargs:\n",
        "        kwargs['weights_only'] = False\n",
        "    return original_load(*args, **kwargs)\n",
        "\n",
        "torch.load = unsafe_load\n",
        "\n",
        "from TTS.api import TTS\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "tts = TTS(model_name=\"tts_models/multilingual/multi-dataset/xtts_v2\", progress_bar=True).to(device)\n",
        "\n",
        "torch.load = original_load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MHrQwwf-E6m"
      },
      "outputs": [],
      "source": [
        "command = \"Wake up, Typist!\"\n",
        "emotions = [\"Happy\", \"Sad\", \"Angry\", \"Dull\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resampler = torchaudio.transforms.Resample(orig_freq=24000, new_freq=16000).to(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FCvOPf1p9uV9"
      },
      "outputs": [],
      "source": [
        "num_of_samples = 200\n",
        "librispeech_files = glob.glob(\"data/raw/LIBRISPEECH/LibriSpeech/dev-clean/**/*.flac\", recursive=True)\n",
        "\n",
        "if not librispeech_files:\n",
        "  print(\"No LibriSpeech files found: downloading dataset...\")\n",
        "  root = Path(\"data/raw/LIBRISPEECH\")\n",
        "  root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  ds = LIBRISPEECH(root=root, url=\"dev-clean\", download=True)\n",
        "\n",
        "  librispeech_files = glob.glob(\"data/raw/LIBRISPEECH/LibriSpeech/dev-clean/**/*.flac\", recursive=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for num in range(num_of_samples):\n",
        "  reference_wav = [random.choice(librispeech_files)]\n",
        "\n",
        "  emotion = random.choice(emotions)\n",
        "\n",
        "  try:\n",
        "    wav = tts.tts(\n",
        "        text=command,\n",
        "        language=\"en\",\n",
        "        emotion=emotion,\n",
        "        temperature=random.uniform(0.7, 0.8),\n",
        "        speaker_wav=reference_wav\n",
        "    )\n",
        "\n",
        "    wav_tensor = torch.tensor(wav).unsqueeze(0).float()\n",
        "    wav_16k = resampler(wav_tensor)\n",
        "\n",
        "    save_path = f\"data/raw/custom/wakeup_dataset/sample_{num}.flac\"\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "    torchaudio.save(save_path, wav_16k, 16000, format=\"flac\")\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Error while generating sample {num}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shutil.make_archive(\"wakeup_dataset\", 'zip', \"data/raw/custom/wakeup_dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "static_commands = [\n",
        "    \"Clear all\",\n",
        "    \"Send all\",\n",
        "    \"Enter all\",\n",
        "    \"Delete last word\",\n",
        "    \"Delete last sentence\",\n",
        "    \"Place dot\",\n",
        "    \"Place period\",\n",
        "    \"New paragraph\",\n",
        "    \"Insert phone number\",\n",
        "    \"Insert mail\",\n",
        "    \"Stop listening\"\n",
        "]\n",
        "\n",
        "random_nouns = [\"apple\", \"table\", \"code\", \"file\", \"text\", \"data\", \"screen\", \"line\", \"word\", \"cat\", \"system\", \"banana\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_dynamic_command():\n",
        "    word1 = random.choice(random_nouns)\n",
        "    word2 = random.choice(random_nouns)\n",
        "    return f\"replace {word1} with {word2}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_files = 0\n",
        "\n",
        "for command in static_commands:\n",
        "    print(f\"Generating: '{command}'\")\n",
        "    for i in range(20):\n",
        "        try:\n",
        "            ref_wav = [random.choice(librispeech_files)]\n",
        "            \n",
        "            wav = tts.tts(\n",
        "                text=command,\n",
        "                language=\"en\", \n",
        "                emotion=random.choice(emotions),\n",
        "                speaker_wav=ref_wav,\n",
        "                temperature=random.uniform(0.7, 0.8)\n",
        "            )\n",
        "            \n",
        "            wav_tensor = torch.tensor(wav).unsqueeze(0).float()\n",
        "            wav_16k = resampler(wav_tensor)\n",
        "            \n",
        "            safe_filename = command.replace(\" \", \"_\").lower()\n",
        "            save_path = f\"data/raw/custom/commands_dataset/{safe_filename}_{i}.flac\"\n",
        "\n",
        "            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "            \n",
        "            torchaudio.save(save_path, wav_16k, 16000, format=\"flac\")\n",
        "            total_files += 1\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Generating dynamic 'replace' command\")\n",
        "\n",
        "for i in range(50):\n",
        "    try:\n",
        "        cmd_text = generate_dynamic_command()\n",
        "        \n",
        "        ref_wav = [random.choice(librispeech_files)]\n",
        "        wav = tts.tts(text=cmd_text, language=\"en\", speaker_wav=ref_wav, emotion=\"Dull\")\n",
        "        \n",
        "        wav_tensor = torch.tensor(wav).unsqueeze(0).float()\n",
        "        wav_16k = resampler(wav_tensor)\n",
        "        \n",
        "        safe_filename = cmd_text.replace(\" \", \"_\").lower()\n",
        "        save_path = f\"data/raw/custom/commands_dataset/dynamic_{safe_filename}_{i}.flac\"\n",
        "        \n",
        "        torchaudio.save(save_path, wav_16k, 16000, format=\"flac\")\n",
        "        total_files += 1\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "shutil.make_archive(\"commands_dataset\", 'zip', \"data/raw/custom/commands_dataset\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "runtime_attributes": {
        "runtime_version": "2025.07"
      }
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
