{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "6f5r66pLef8o",
        "outputId": "b4a831b4-dce4-49ee-f4fc-5f2948faf682"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.35.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sjL9nKbycylz"
      },
      "outputs": [],
      "source": [
        "from torchaudio.datasets import LIBRISPEECH\n",
        "from pathlib import Path\n",
        "import torchaudio\n",
        "from transformers import (\n",
        "    Wav2Vec2CTCTokenizer,\n",
        "    Wav2Vec2ForCTC,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    logging\n",
        ")\n",
        "from torch.utils.data import Dataset\n",
        "import evaluate\n",
        "import torch\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "logging.set_verbosity_error()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading dataset\n",
        "root = Path(\"data/raw/LIBRISPEECH\")\n",
        "root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "train_dataset = LIBRISPEECH(root=root, url=\"train-clean-100\", download=True)\n",
        "eval_dataset = LIBRISPEECH(root=root, url=\"dev-clean\", download=True)\n"
      ],
      "metadata": {
        "id": "F1JQtDGuc8cN",
        "outputId": "3f7028ca-7193-42f4-a5c7-73eb5630b7d8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.95G/5.95G [05:28<00:00, 19.4MB/s]\n",
            "100%|██████████| 322M/322M [00:17<00:00, 19.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizing transcripts\n",
        "tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(\"facebook/wav2vec2-base\")\n",
        "\n",
        "class LibriSpeechDataset(Dataset):\n",
        "    def __init__(self, torchaudio_dataset, tokenizer):\n",
        "        self.dataset = torchaudio_dataset\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.dataset[idx]\n",
        "\n",
        "        if len(data) == 2:\n",
        "            waveform, sr = data\n",
        "            transcript = \"\"\n",
        "        else:\n",
        "            waveform, sr, transcript, *_ = data\n",
        "\n",
        "        if sr != 16000:\n",
        "            waveform = torchaudio.transforms.Resample(sr, 16000)(waveform)\n",
        "        input_values = waveform.squeeze(0).numpy()\n",
        "        labels = self.tokenizer(transcript).input_ids\n",
        "        return {\"input_values\": input_values, \"labels\": labels}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "\n",
        "train_dataset = LibriSpeechDataset(train_dataset, tokenizer)\n",
        "eval_dataset = LibriSpeechDataset(eval_dataset, tokenizer)\n"
      ],
      "metadata": {
        "id": "5niIlcGsdCIt",
        "outputId": "33890ac6-caf5-485a-be27-f3affda230f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
            ],
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]"
            ],
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
            ],
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initializing wav2vec2 model\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base\")\n",
        "model.freeze_feature_encoder()\n",
        "\n",
        "def data_collator(batch):\n",
        "    input_values = [torch.tensor(b[\"input_values\"]) for b in batch]\n",
        "    labels = [torch.tensor(b[\"labels\"]) for b in batch]\n",
        "\n",
        "    input_values = torch.nn.utils.rnn.pad_sequence(input_values, batch_first=True)\n",
        "    labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=-100)\n",
        "\n",
        "    return {\"input_values\": input_values, \"labels\": labels}\n"
      ],
      "metadata": {
        "id": "zve6Kq9ndFAQ",
        "outputId": "f947f900-5706-46bf-8b18-26dfc12f4544"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/380M [00:00<?, ?B/s]"
            ],
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --no-cache-dir jiwer"
      ],
      "metadata": {
        "id": "UwXkeQzbhoVZ",
        "outputId": "2f2f7d86-eea2-4a5c-f245-b792b5ac97c3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jiwer\n",
            "  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from jiwer) (8.3.0)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
            "  Downloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Downloading jiwer-4.0.0-py3-none-any.whl (23 kB)\n",
            "Downloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-4.0.0 rapidfuzz-3.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training, fine-tuning\n",
        "\n",
        "wer_metric = evaluate.load(\"wer\")\n",
        "cer_metric = evaluate.load(\"cer\")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    pred_logits = pred.predictions\n",
        "    pred_ids = torch.argmax(torch.tensor(pred_logits), dim=-1)\n",
        "\n",
        "    # decode\n",
        "    pred_str = tokenizer.batch_decode(pred_ids)\n",
        "    label_ids = pred.label_ids\n",
        "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
        "    label_str = tokenizer.batch_decode(label_ids)\n",
        "\n",
        "    return {\n",
        "        \"wer\": wer_metric.compute(predictions=pred_str, references=label_str),\n",
        "        \"cer\": cer_metric.compute(predictions=pred_str, references=label_str)\n",
        "    }\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=2,\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=50,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    max_grad_norm=1.0,\n",
        "    gradient_accumulation_steps=2,\n",
        "    report_to=[],\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "42nIMf1OdItW",
        "outputId": "f61de7ae-add4-414f-9d0c-6a154d61e0ed"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 12621.5613, 'grad_norm': 13906.1279296875, 'learning_rate': 9.862668161434978e-06, 'epoch': 0.028026905829596414}\n",
            "{'loss': 4816.9197, 'grad_norm': 1839.320068359375, 'learning_rate': 9.722533632286997e-06, 'epoch': 0.05605381165919283}\n",
            "{'loss': 4453.6809, 'grad_norm': 2015.767578125, 'learning_rate': 9.582399103139015e-06, 'epoch': 0.08408071748878924}\n",
            "{'loss': 4351.3872, 'grad_norm': 1736.87109375, 'learning_rate': 9.442264573991032e-06, 'epoch': 0.11210762331838565}\n",
            "{'loss': 4373.7825, 'grad_norm': 2047.0941162109375, 'learning_rate': 9.30213004484305e-06, 'epoch': 0.14013452914798205}\n",
            "{'loss': 4323.9197, 'grad_norm': 1569.660888671875, 'learning_rate': 9.161995515695067e-06, 'epoch': 0.1681614349775785}\n",
            "{'loss': 4298.5866, 'grad_norm': 1651.0101318359375, 'learning_rate': 9.021860986547086e-06, 'epoch': 0.1961883408071749}\n",
            "{'loss': 4271.3366, 'grad_norm': 1591.7454833984375, 'learning_rate': 8.881726457399104e-06, 'epoch': 0.2242152466367713}\n",
            "{'loss': 4301.1, 'grad_norm': 761.6309204101562, 'learning_rate': 8.741591928251121e-06, 'epoch': 0.2522421524663677}\n",
            "{'loss': 4250.6287, 'grad_norm': 935.6663818359375, 'learning_rate': 8.60145739910314e-06, 'epoch': 0.2802690582959641}\n",
            "{'loss': 4270.8912, 'grad_norm': 963.4846801757812, 'learning_rate': 8.461322869955158e-06, 'epoch': 0.30829596412556054}\n",
            "{'loss': 4154.7603, 'grad_norm': 1097.1639404296875, 'learning_rate': 8.321188340807175e-06, 'epoch': 0.336322869955157}\n",
            "{'loss': 4261.9509, 'grad_norm': 698.1499633789062, 'learning_rate': 8.181053811659193e-06, 'epoch': 0.36434977578475336}\n",
            "{'loss': 4278.6697, 'grad_norm': 718.3318481445312, 'learning_rate': 8.040919282511212e-06, 'epoch': 0.3923766816143498}\n",
            "{'loss': 4210.8172, 'grad_norm': 1213.4075927734375, 'learning_rate': 7.90078475336323e-06, 'epoch': 0.4204035874439462}\n",
            "{'loss': 4186.9425, 'grad_norm': 678.59423828125, 'learning_rate': 7.760650224215247e-06, 'epoch': 0.4484304932735426}\n",
            "{'loss': 4175.9987, 'grad_norm': 905.0358276367188, 'learning_rate': 7.6205156950672654e-06, 'epoch': 0.476457399103139}\n",
            "{'loss': 4242.1794, 'grad_norm': 393.8056335449219, 'learning_rate': 7.480381165919283e-06, 'epoch': 0.5044843049327354}\n",
            "{'loss': 4238.4113, 'grad_norm': 564.990234375, 'learning_rate': 7.340246636771301e-06, 'epoch': 0.5325112107623319}\n",
            "{'loss': 4268.0378, 'grad_norm': 713.0709228515625, 'learning_rate': 7.2001121076233196e-06, 'epoch': 0.5605381165919282}\n",
            "{'loss': 4185.1172, 'grad_norm': 1071.262939453125, 'learning_rate': 7.059977578475336e-06, 'epoch': 0.5885650224215246}\n",
            "{'loss': 4192.9237, 'grad_norm': 1342.136962890625, 'learning_rate': 6.919843049327355e-06, 'epoch': 0.6165919282511211}\n",
            "{'loss': 4259.0272, 'grad_norm': 849.9244995117188, 'learning_rate': 6.779708520179372e-06, 'epoch': 0.6446188340807175}\n",
            "{'loss': 4224.7644, 'grad_norm': 548.450927734375, 'learning_rate': 6.63957399103139e-06, 'epoch': 0.672645739910314}\n",
            "{'loss': 4237.9025, 'grad_norm': 1834.7181396484375, 'learning_rate': 6.499439461883409e-06, 'epoch': 0.7006726457399103}\n",
            "{'loss': 4078.695, 'grad_norm': 1568.2791748046875, 'learning_rate': 6.359304932735426e-06, 'epoch': 0.7286995515695067}\n",
            "{'loss': 3855.3044, 'grad_norm': 1503.1116943359375, 'learning_rate': 6.2191704035874444e-06, 'epoch': 0.7567264573991032}\n",
            "{'loss': 3591.2975, 'grad_norm': 1650.65380859375, 'learning_rate': 6.079035874439463e-06, 'epoch': 0.7847533632286996}\n",
            "{'loss': 3248.4084, 'grad_norm': 1875.02783203125, 'learning_rate': 5.93890134529148e-06, 'epoch': 0.8127802690582959}\n",
            "{'loss': 2976.0075, 'grad_norm': 2649.27587890625, 'learning_rate': 5.798766816143499e-06, 'epoch': 0.8408071748878924}\n",
            "{'loss': 2691.4322, 'grad_norm': 2379.6943359375, 'learning_rate': 5.658632286995516e-06, 'epoch': 0.8688340807174888}\n",
            "{'loss': 2412.3597, 'grad_norm': 2131.361083984375, 'learning_rate': 5.518497757847534e-06, 'epoch': 0.8968609865470852}\n",
            "{'loss': 2187.6059, 'grad_norm': 2081.032470703125, 'learning_rate': 5.378363228699553e-06, 'epoch': 0.9248878923766816}\n",
            "{'loss': 1981.8166, 'grad_norm': 2065.243896484375, 'learning_rate': 5.238228699551569e-06, 'epoch': 0.952914798206278}\n",
            "{'loss': 1786.2955, 'grad_norm': 2058.56787109375, 'learning_rate': 5.098094170403588e-06, 'epoch': 0.9809417040358744}\n",
            "{'eval_loss': 868.783203125, 'eval_wer': 0.5875886915922208, 'eval_cer': 0.19182666652530841, 'eval_runtime': 95.2984, 'eval_samples_per_second': 28.364, 'eval_steps_per_second': 3.547, 'epoch': 1.0}\n",
            "{'loss': 1641.0213, 'grad_norm': 2484.9072265625, 'learning_rate': 4.957959641255606e-06, 'epoch': 1.0089686098654709}\n",
            "{'loss': 1581.0489, 'grad_norm': 1872.7911376953125, 'learning_rate': 4.8178251121076235e-06, 'epoch': 1.0369955156950672}\n",
            "{'loss': 1466.8473, 'grad_norm': 1830.658935546875, 'learning_rate': 4.677690582959642e-06, 'epoch': 1.0650224215246638}\n",
            "{'loss': 1403.8198, 'grad_norm': 1840.1986083984375, 'learning_rate': 4.53755605381166e-06, 'epoch': 1.09304932735426}\n",
            "{'loss': 1352.5927, 'grad_norm': 1797.7110595703125, 'learning_rate': 4.397421524663678e-06, 'epoch': 1.1210762331838564}\n",
            "{'loss': 1288.2245, 'grad_norm': 1999.249267578125, 'learning_rate': 4.257286995515695e-06, 'epoch': 1.149103139013453}\n",
            "{'loss': 1271.1102, 'grad_norm': 2100.90576171875, 'learning_rate': 4.117152466367713e-06, 'epoch': 1.1771300448430493}\n",
            "{'loss': 1220.6088, 'grad_norm': 1696.5513916015625, 'learning_rate': 3.977017937219732e-06, 'epoch': 1.2051569506726458}\n",
            "{'loss': 1184.78, 'grad_norm': 1974.3656005859375, 'learning_rate': 3.836883408071749e-06, 'epoch': 1.2331838565022422}\n",
            "{'loss': 1149.3324, 'grad_norm': 1987.841796875, 'learning_rate': 3.696748878923767e-06, 'epoch': 1.2612107623318385}\n",
            "{'loss': 1120.8402, 'grad_norm': 1840.23291015625, 'learning_rate': 3.556614349775785e-06, 'epoch': 1.289237668161435}\n",
            "{'loss': 1093.2906, 'grad_norm': 1771.039794921875, 'learning_rate': 3.4164798206278025e-06, 'epoch': 1.3172645739910314}\n",
            "{'loss': 1091.1564, 'grad_norm': 1973.7801513671875, 'learning_rate': 3.2763452914798212e-06, 'epoch': 1.3452914798206277}\n",
            "{'loss': 1041.087, 'grad_norm': 1813.8072509765625, 'learning_rate': 3.1362107623318387e-06, 'epoch': 1.3733183856502242}\n",
            "{'loss': 1012.4734, 'grad_norm': 1690.9375, 'learning_rate': 2.9960762331838566e-06, 'epoch': 1.4013452914798206}\n",
            "{'loss': 1011.5862, 'grad_norm': 1864.59619140625, 'learning_rate': 2.8559417040358745e-06, 'epoch': 1.4293721973094171}\n",
            "{'loss': 1000.8877, 'grad_norm': 2336.60791015625, 'learning_rate': 2.715807174887893e-06, 'epoch': 1.4573991031390134}\n",
            "{'loss': 976.7952, 'grad_norm': 1877.4169921875, 'learning_rate': 2.5756726457399107e-06, 'epoch': 1.4854260089686098}\n",
            "{'loss': 961.1598, 'grad_norm': 1946.808349609375, 'learning_rate': 2.4355381165919282e-06, 'epoch': 1.5134529147982063}\n",
            "{'loss': 950.3997, 'grad_norm': 1794.8387451171875, 'learning_rate': 2.2954035874439466e-06, 'epoch': 1.5414798206278026}\n",
            "{'loss': 947.1189, 'grad_norm': 1826.0306396484375, 'learning_rate': 2.1552690582959645e-06, 'epoch': 1.5695067264573992}\n",
            "{'loss': 919.7991, 'grad_norm': 1591.9913330078125, 'learning_rate': 2.0151345291479824e-06, 'epoch': 1.5975336322869955}\n",
            "{'loss': 910.3837, 'grad_norm': 1747.7445068359375, 'learning_rate': 1.8750000000000003e-06, 'epoch': 1.6255605381165918}\n",
            "{'loss': 918.1716, 'grad_norm': 1673.272216796875, 'learning_rate': 1.734865470852018e-06, 'epoch': 1.6535874439461884}\n",
            "{'loss': 893.9206, 'grad_norm': 1656.0653076171875, 'learning_rate': 1.594730941704036e-06, 'epoch': 1.6816143497757847}\n",
            "{'loss': 900.4423, 'grad_norm': 1961.6903076171875, 'learning_rate': 1.4545964125560538e-06, 'epoch': 1.7096412556053813}\n",
            "{'loss': 890.3713, 'grad_norm': 1722.2491455078125, 'learning_rate': 1.3144618834080719e-06, 'epoch': 1.7376681614349776}\n",
            "{'loss': 873.0914, 'grad_norm': 1765.6666259765625, 'learning_rate': 1.1743273542600898e-06, 'epoch': 1.765695067264574}\n",
            "{'loss': 890.4032, 'grad_norm': 1680.235107421875, 'learning_rate': 1.0341928251121077e-06, 'epoch': 1.7937219730941703}\n",
            "{'loss': 875.1115, 'grad_norm': 1671.8134765625, 'learning_rate': 8.940582959641256e-07, 'epoch': 1.8217488789237668}\n",
            "{'loss': 886.3225, 'grad_norm': 2031.96875, 'learning_rate': 7.539237668161435e-07, 'epoch': 1.8497757847533634}\n",
            "{'loss': 875.9348, 'grad_norm': 1905.1680908203125, 'learning_rate': 6.137892376681615e-07, 'epoch': 1.8778026905829597}\n",
            "{'loss': 862.693, 'grad_norm': 1699.0595703125, 'learning_rate': 4.736547085201794e-07, 'epoch': 1.905829596412556}\n",
            "{'loss': 859.5834, 'grad_norm': 1655.2313232421875, 'learning_rate': 3.3352017937219734e-07, 'epoch': 1.9338565022421523}\n",
            "{'loss': 864.4986, 'grad_norm': 1565.327392578125, 'learning_rate': 1.9338565022421527e-07, 'epoch': 1.9618834080717489}\n",
            "{'loss': 861.3897, 'grad_norm': 1790.1829833984375, 'learning_rate': 5.3251121076233184e-08, 'epoch': 1.9899103139013454}\n",
            "{'eval_loss': 433.98602294921875, 'eval_wer': 0.3444358663284438, 'eval_cer': 0.09733575055924854, 'eval_runtime': 93.5669, 'eval_samples_per_second': 28.888, 'eval_steps_per_second': 3.612, 'epoch': 2.0}\n",
            "{'train_runtime': 5410.6273, 'train_samples_per_second': 10.549, 'train_steps_per_second': 0.659, 'train_loss': 2559.048037131271, 'epoch': 2.0}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3568, training_loss=2559.048037131271, metrics={'train_runtime': 5410.6273, 'train_samples_per_second': 10.549, 'train_steps_per_second': 0.659, 'train_loss': 2559.048037131271, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# metrics\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Validation WER: {eval_results['eval_wer']:.4f}\")\n",
        "print(f\"Validation CER: {eval_results['eval_cer']:.4f}\")"
      ],
      "metadata": {
        "id": "1HEO5V7BdLPP",
        "outputId": "5997d308-4450-4054-986c-dad0a4042c3d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 433.98602294921875, 'eval_wer': 0.3444358663284438, 'eval_cer': 0.09733575055924854, 'eval_runtime': 91.6491, 'eval_samples_per_second': 29.493, 'eval_steps_per_second': 3.688, 'epoch': 2.0}\n",
            "Validation WER: 0.3444\n",
            "Validation CER: 0.0973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = LIBRISPEECH(root=root, url=\"test-clean\", download=True)\n",
        "test_dataset = LibriSpeechDataset(test_dataset, tokenizer)"
      ],
      "metadata": {
        "id": "bqYYHMn0eBpH"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = trainer.evaluate(test_dataset)\n",
        "print(f\"Test WER: {test_results['eval_wer']:.4f}\")\n",
        "print(f\"Test CER: {test_results['eval_cer']:.4f}\")"
      ],
      "metadata": {
        "id": "ql3ItyifeMBF",
        "outputId": "83ee9098-5f47-469b-e7db-82d0a383ab7b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 444.38134765625, 'eval_wer': 0.3518905964698722, 'eval_cer': 0.09871712264799785, 'eval_runtime': 95.7412, 'eval_samples_per_second': 27.365, 'eval_steps_per_second': 3.426, 'epoch': 2.0}\n",
            "Test WER: 0.3519\n",
            "Test CER: 0.0987\n"
          ]
        }
      ]
    }
  ]
}
